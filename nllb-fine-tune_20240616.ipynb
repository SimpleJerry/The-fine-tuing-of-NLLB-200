{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6cb62a25-f9dc-4ab0-ad41-925ad49d350d",
   "metadata": {},
   "source": [
    "Environment Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b217e314-3a45-4abb-bbf4-fd1b3901bc2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: transformers in ./miniconda3/lib/python3.12/site-packages (4.41.2)\n",
      "Requirement already satisfied: accelerate in ./miniconda3/lib/python3.12/site-packages (0.31.0)\n",
      "Requirement already satisfied: scikit-learn in ./miniconda3/lib/python3.12/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy in ./miniconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in ./miniconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.12/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in ./miniconda3/lib/python3.12/site-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniconda3/lib/python3.12/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./miniconda3/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./miniconda3/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./miniconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: psutil in ./miniconda3/lib/python3.12/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./miniconda3/lib/python3.12/site-packages (from accelerate) (2.3.0+cu121)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
      "Requirement already satisfied: networkx in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./miniconda3/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "#å®‰è£…transformersåº“\n",
    "!pip install transformers accelerate scikit-learn numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2d71c2c68a230",
   "metadata": {},
   "source": [
    "Load the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e591ab0d8c7532",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_disk_dir = \"autodl-tmp\"  # æ•°æ®ç›˜dirï¼ˆäº‘GPUå¹³å°ï¼‰\n",
    "model_name = \"nllb-200-distilled-600M\"\n",
    "model_dir = os.path.join(data_disk_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "772dbf8a-eb10-4a50-9b1e-683a973649da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, tgt_lang=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0064f69-3dcc-4b70-9945-a6d8e4ecd1c6",
   "metadata": {},
   "source": [
    "Prepare your training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104c0cf739ab273c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"data/027.í•œêµ­ì–´-ì¤‘êµ­ì–´_ë²ˆì—­_ë§ë­‰ì¹˜_1/01.ë°ì´í„°\"\n",
    "csv_train = os.path.join(data_dir, \"1.Training/ì›ì²œë°ì´í„°/ko2zh_patent_1_training.csv\")\n",
    "csv_valid = os.path.join(data_dir, \"2.Validation/ì›ì²œë°ì´í„°/ko2zh_patent_2_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a503105-8bce-44cc-a840-fbd3ebf8924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\"ì¤‘êµ­ì–´\": \"zho_Hans\", \"í•œêµ­ì–´\": \"kor_Hang\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d46a4e-c959-4431-a1bc-e407723078c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "#load Training Data\n",
    "df_train = pd.read_csv(csv_train)[rename_dict.keys()]\n",
    "df_train.rename(columns=rename_dict, inplace=True)  # rename the columns\n",
    "\n",
    "#load Validation Data\n",
    "df_valid = pd.read_csv(csv_valid)[rename_dict.keys()]\n",
    "df_valid.rename(columns=rename_dict, inplace=True)  # rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22c9918d-2b9d-44d5-b8b6-33258bc8656f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zho_Hans</th>\n",
       "      <th>kor_Hang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>æœ¬å‘æ˜å¯ä»¥æ£€æµ‹é€šè¿‡æ’å¤´ä¾›åº”çš„ä¸»ç”µæºçš„é¢‘ç‡ç‰¹æ€§,å¹¶ä¸ºä½¿ä»æ¥è¿‘è¯¥é¢‘ç‡é›¶ç”µä½çš„ä¸Šå‡ç”µä½è¿æ¥åˆ°ç»§ç”µå™¨...</td>\n",
       "      <td>ë³¸ ë°œëª…ì€ í”ŒëŸ¬ê·¸ë¥¼ í†µí•´ ê³µê¸‰ë˜ëŠ” ì£¼ì „ì›ì˜ ì£¼íŒŒìˆ˜ íŠ¹ì„±ì„ ê²€ì¶œí•˜ì—¬ ì£¼íŒŒìˆ˜ì˜ ì œë¡œì „ìœ„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>æœ¬å‘æ˜æ˜¯å…³äºèœ‚çªç”µè¯çš„å‘æ˜,å½“ç”±äºæ‰‹æœºçš„ç§»åŠ¨è€Œç¦»å¼€æœåŠ¡åŒºåŸŸè¶…è¿‡é¢„å®šæ—¶é—´æ—¶è‡ªåŠ¨å…³é—­ç”µæº,å¹¶ä»¥é¢„...</td>\n",
       "      <td>ë³¸ ë°œëª…ì€ ì…€ë£°ë¼í°ì— ê´€í•œ ê²ƒìœ¼ë¡œ, ì…€ë£°ë¼í°ì˜ ì´ë™ìœ¼ë¡œ ì†Œì •ì‹œê°„ì´ìƒ ì„œì–´ë¹„ìŠ¤ ì§€ì—­ì„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>å¦å¤–,å› ä¸ºä¸æ‰§è¡Œåˆ©ç”¨å•å…ƒå¤šåŠŸèƒ½å¤åˆ¶çš„èµ„æºç®¡ç†,æ‰€ä»¥å­˜åœ¨æ— æ³•å‘å¤šä¸ªç”¨æˆ·æä¾›åŒä¸€ä¸ªéŸ³è°ƒçš„ç¼ºç‚¹ã€‚</td>\n",
       "      <td>ë˜í•œ, ì…€ ë©€í‹° ì¹´í”¼ ê¸°ëŠ¥ì„ í™œìš©í•˜ê¸° ìœ„í•œ ìì› ê´€ë¦¬ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— í•˜ë‚˜ì˜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>å®‰è£…æœ‰ç¼–ç å™¨çš„ç”µåŠ¨æœº,å¯ä»¥æµ‹é‡å›è½¬é‡å’Œå›è½¬é€Ÿåº¦ã€‚</td>\n",
       "      <td>ì—”ì½”ë”ê°€ ë¶€ì°©ëœ ëª¨í„°ì˜ ê²½ìš° íšŒì „ëŸ‰ê³¼ íšŒì „ ì†ë„ë¥¼ ì¸¡ì •í•  ìˆ˜ ìˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>æœ¬å‘æ˜æ˜¯å…³äºä¸€ç§ç”¨äºä¿æŠ¤çœŸç©ºæ³µçš„ç”µåŠ¨æœº,å…å—åŠå¯¼ä½“æº…å°„(Sputtering)è®¾å¤‡ä¸­çš„è¿‡ç”µæµ...</td>\n",
       "      <td>ë³¸ ë°œëª…ì€ ë°˜ë„ì²´ ìŠ¤í¼í„°ë§(Sputtering)ì¥ë¹„ì— ìˆì–´ì„œ, ì§„ê³µ íŒí”„ì˜ ëª¨í„°ë¥¼ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>æœ¬å‘æ˜æ¶‰åŠä¸€ç§ç”¨äºåœ¨æä¾›èƒŒæ™¯å£°éŸ³å‘¼å«æœåŠ¡æ—¶æ”¹å–„èƒŒæ™¯éŸ³ä¹çš„å£°éŸ³è´¨é‡æ–¹æ³•ã€‚</td>\n",
       "      <td>ë³¸ ë°œëª…ì€ ë°°ê²½ìŒ í†µí™” ì„œë¹„ìŠ¤ ì œê³µì‹œì— ë°°ê²½ìŒì•…ì˜ ìŒì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ë°©ë²•ì— ê´€...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>å¯ä»¥å°†ç”µæµé‡Šæ”¾é˜»æŠ—è®¾ç½®å¾—è¾ƒä½,æä¾›ä¸€ç§é«˜åº¦æ–¹ä¾¿çš„ç”µæ± è£…ç½®ã€‚</td>\n",
       "      <td>ê³¼ì „ë¥˜ í•´ì œ ì„í”¼ë˜ìŠ¤ë¥¼ ë‚®ê²Œ ì„¤ì •í•  ìˆ˜ ìˆì–´, í¸ë¦¬ì„±ì´ ë†’ì€ ë°°í„°ë¦¬ ì¥ì¹˜ë¥¼ ì œê³µí•œë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>æœ¬å‘æ˜çš„ç›®çš„æ˜¯ä¼˜åŒ–å¯†å°æ„ä»¶çš„å¸ƒç½®,è¯¥å¯†å°æ„ä»¶é˜»æ­¢å·¥è‰ºè…”ä½“çš„å†…éƒ¨ä¸å¤§æ°”ä¹‹é—´çš„è¿é€šã€‚</td>\n",
       "      <td>ë³¸ ë°œëª…ì˜ ê³¼ì œëŠ” ì²˜ë¦¬ì‹¤ ë‚´ì™€ ëŒ€ê¸°ì˜ ì—°í†µì„ ì°¨ë‹¨í•˜ëŠ” ë°€ë´‰ ë¶€ì¬ì˜ ë°°ì¹˜ì˜ ì ì •í™”ë¥¼ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>å¦å¤–,æœ¬å‘æ˜åŒ…æ‹¬å›ºå®šä½“ç¼“å†²è£…ç½®,å› æ­¤å‡è½»å†²å‡»æ¥è·å¾—é˜²æ­¢ç»ç¼˜ä½“ç ´è£‚çš„æ•ˆæœã€‚</td>\n",
       "      <td>ë˜í•œ, ë³¸ ë°œëª…ì€ ê³ ì •ì²´ ì™„ì¶©ìˆ˜ë‹¨ì´ í¬í•¨ë˜ì–´ ìˆì–´ ì¶©ê²©ì„ ì™„í™”ì‹œí‚´ìœ¼ë¡œì¨ ì• ì íŒŒì†ì„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>åœ¨å¸¸è§„çš„å¤šè¾“å…¥è°æŒ¯DC-DCè½¬æ¢å™¨ä¸­,ç”±äºä¸èƒ½åœ¨å˜å‹å™¨çš„æ¬¡çº§ä¾§ä¸Šä½¿ç”¨æ„Ÿæ€§è´Ÿè½½,å› æ­¤éš¾ä»¥æé«˜æ•ˆ...</td>\n",
       "      <td>ì¢…ë˜ ê¸°ìˆ ì— ì˜í•œ ë‹¤ì¤‘ ì…ë ¥ ê³µì§„í˜• DC-DC ì»¨ë²„í„°ì—ì„œëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ 2ì°¨ ì¸¡ì— ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 zho_Hans  \\\n",
       "0       æœ¬å‘æ˜å¯ä»¥æ£€æµ‹é€šè¿‡æ’å¤´ä¾›åº”çš„ä¸»ç”µæºçš„é¢‘ç‡ç‰¹æ€§,å¹¶ä¸ºä½¿ä»æ¥è¿‘è¯¥é¢‘ç‡é›¶ç”µä½çš„ä¸Šå‡ç”µä½è¿æ¥åˆ°ç»§ç”µå™¨...   \n",
       "1       æœ¬å‘æ˜æ˜¯å…³äºèœ‚çªç”µè¯çš„å‘æ˜,å½“ç”±äºæ‰‹æœºçš„ç§»åŠ¨è€Œç¦»å¼€æœåŠ¡åŒºåŸŸè¶…è¿‡é¢„å®šæ—¶é—´æ—¶è‡ªåŠ¨å…³é—­ç”µæº,å¹¶ä»¥é¢„...   \n",
       "2           å¦å¤–,å› ä¸ºä¸æ‰§è¡Œåˆ©ç”¨å•å…ƒå¤šåŠŸèƒ½å¤åˆ¶çš„èµ„æºç®¡ç†,æ‰€ä»¥å­˜åœ¨æ— æ³•å‘å¤šä¸ªç”¨æˆ·æä¾›åŒä¸€ä¸ªéŸ³è°ƒçš„ç¼ºç‚¹ã€‚   \n",
       "3                                å®‰è£…æœ‰ç¼–ç å™¨çš„ç”µåŠ¨æœº,å¯ä»¥æµ‹é‡å›è½¬é‡å’Œå›è½¬é€Ÿåº¦ã€‚   \n",
       "4       æœ¬å‘æ˜æ˜¯å…³äºä¸€ç§ç”¨äºä¿æŠ¤çœŸç©ºæ³µçš„ç”µåŠ¨æœº,å…å—åŠå¯¼ä½“æº…å°„(Sputtering)è®¾å¤‡ä¸­çš„è¿‡ç”µæµ...   \n",
       "...                                                   ...   \n",
       "119995                æœ¬å‘æ˜æ¶‰åŠä¸€ç§ç”¨äºåœ¨æä¾›èƒŒæ™¯å£°éŸ³å‘¼å«æœåŠ¡æ—¶æ”¹å–„èƒŒæ™¯éŸ³ä¹çš„å£°éŸ³è´¨é‡æ–¹æ³•ã€‚   \n",
       "119996                      å¯ä»¥å°†ç”µæµé‡Šæ”¾é˜»æŠ—è®¾ç½®å¾—è¾ƒä½,æä¾›ä¸€ç§é«˜åº¦æ–¹ä¾¿çš„ç”µæ± è£…ç½®ã€‚   \n",
       "119997           æœ¬å‘æ˜çš„ç›®çš„æ˜¯ä¼˜åŒ–å¯†å°æ„ä»¶çš„å¸ƒç½®,è¯¥å¯†å°æ„ä»¶é˜»æ­¢å·¥è‰ºè…”ä½“çš„å†…éƒ¨ä¸å¤§æ°”ä¹‹é—´çš„è¿é€šã€‚   \n",
       "119998               å¦å¤–,æœ¬å‘æ˜åŒ…æ‹¬å›ºå®šä½“ç¼“å†²è£…ç½®,å› æ­¤å‡è½»å†²å‡»æ¥è·å¾—é˜²æ­¢ç»ç¼˜ä½“ç ´è£‚çš„æ•ˆæœã€‚   \n",
       "119999  åœ¨å¸¸è§„çš„å¤šè¾“å…¥è°æŒ¯DC-DCè½¬æ¢å™¨ä¸­,ç”±äºä¸èƒ½åœ¨å˜å‹å™¨çš„æ¬¡çº§ä¾§ä¸Šä½¿ç”¨æ„Ÿæ€§è´Ÿè½½,å› æ­¤éš¾ä»¥æé«˜æ•ˆ...   \n",
       "\n",
       "                                                 kor_Hang  \n",
       "0       ë³¸ ë°œëª…ì€ í”ŒëŸ¬ê·¸ë¥¼ í†µí•´ ê³µê¸‰ë˜ëŠ” ì£¼ì „ì›ì˜ ì£¼íŒŒìˆ˜ íŠ¹ì„±ì„ ê²€ì¶œí•˜ì—¬ ì£¼íŒŒìˆ˜ì˜ ì œë¡œì „ìœ„...  \n",
       "1       ë³¸ ë°œëª…ì€ ì…€ë£°ë¼í°ì— ê´€í•œ ê²ƒìœ¼ë¡œ, ì…€ë£°ë¼í°ì˜ ì´ë™ìœ¼ë¡œ ì†Œì •ì‹œê°„ì´ìƒ ì„œì–´ë¹„ìŠ¤ ì§€ì—­ì„...  \n",
       "2       ë˜í•œ, ì…€ ë©€í‹° ì¹´í”¼ ê¸°ëŠ¥ì„ í™œìš©í•˜ê¸° ìœ„í•œ ìì› ê´€ë¦¬ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— í•˜ë‚˜ì˜...  \n",
       "3                   ì—”ì½”ë”ê°€ ë¶€ì°©ëœ ëª¨í„°ì˜ ê²½ìš° íšŒì „ëŸ‰ê³¼ íšŒì „ ì†ë„ë¥¼ ì¸¡ì •í•  ìˆ˜ ìˆë‹¤.  \n",
       "4       ë³¸ ë°œëª…ì€ ë°˜ë„ì²´ ìŠ¤í¼í„°ë§(Sputtering)ì¥ë¹„ì— ìˆì–´ì„œ, ì§„ê³µ íŒí”„ì˜ ëª¨í„°ë¥¼ ...  \n",
       "...                                                   ...  \n",
       "119995  ë³¸ ë°œëª…ì€ ë°°ê²½ìŒ í†µí™” ì„œë¹„ìŠ¤ ì œê³µì‹œì— ë°°ê²½ìŒì•…ì˜ ìŒì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ë°©ë²•ì— ê´€...  \n",
       "119996    ê³¼ì „ë¥˜ í•´ì œ ì„í”¼ë˜ìŠ¤ë¥¼ ë‚®ê²Œ ì„¤ì •í•  ìˆ˜ ìˆì–´, í¸ë¦¬ì„±ì´ ë†’ì€ ë°°í„°ë¦¬ ì¥ì¹˜ë¥¼ ì œê³µí•œë‹¤.  \n",
       "119997  ë³¸ ë°œëª…ì˜ ê³¼ì œëŠ” ì²˜ë¦¬ì‹¤ ë‚´ì™€ ëŒ€ê¸°ì˜ ì—°í†µì„ ì°¨ë‹¨í•˜ëŠ” ë°€ë´‰ ë¶€ì¬ì˜ ë°°ì¹˜ì˜ ì ì •í™”ë¥¼ ...  \n",
       "119998  ë˜í•œ, ë³¸ ë°œëª…ì€ ê³ ì •ì²´ ì™„ì¶©ìˆ˜ë‹¨ì´ í¬í•¨ë˜ì–´ ìˆì–´ ì¶©ê²©ì„ ì™„í™”ì‹œí‚´ìœ¼ë¡œì¨ ì• ì íŒŒì†ì„...  \n",
       "119999  ì¢…ë˜ ê¸°ìˆ ì— ì˜í•œ ë‹¤ì¤‘ ì…ë ¥ ê³µì§„í˜• DC-DC ì»¨ë²„í„°ì—ì„œëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ 2ì°¨ ì¸¡ì— ...  \n",
       "\n",
       "[120000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "879de305-49f1-46c3-9046-b9406323b8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zho_Hans</th>\n",
       "      <th>kor_Hang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>æœ¬æ–¹æ¡ˆçš„æ¥è§¦é¢è†¨èƒ€å‹çƒ­ç†”æ–­å™¨æ¶‰åŠç”¨äºåŠ çƒ­è£…ç½®æˆ–åŠ çƒ­éƒ¨çš„æ¥è§¦é¢è†¨èƒ€å¹¶ä¸”æ”¹å–„æ¥è§¦çŠ¶æ€çš„çƒ­ç†”æ–­å™¨ã€‚</td>\n",
       "      <td>ë³¸ ê³ ì•ˆì˜ ì ‘ë©´í™•ì¥ ê°ì˜¨í“¨ì¦ˆëŠ”, ë°œì—´ê¸°êµ¬ë‚˜ ë°œì—´ë¶€ìœ„ì— ëŒ€í•œ ì ‘ì´‰ë©´ì„ í™•ì¥ì‹œí‚´ê³¼ ë™ì‹œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>å¯ä»¥æ²¿ç€åˆ‡å‰²çº¿é«˜ç²¾åº¦åœ°åˆ‡å‰²è¦åŠ å·¥çš„ç‰©ä½“ã€‚</td>\n",
       "      <td>ì ˆë‹¨ ì˜ˆì • ë¼ì¸ì— ë”°ë¥¸ ê°€ê³µ ëŒ€ìƒë¬¼ì˜ ê³ ì •ë°€ë„ ì ˆë‹¨ì´ ê°€ëŠ¥í•˜ê²Œ ëœë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>æ ¹æ®æœ¬å‘æ˜,æœ‰æ•ˆåœ°æ¸…æ´äº†é“œ(Cu)å¸ƒçº¿å·¥è‰ºä¸­äº§ç”Ÿçš„å—æ±¡æŸ“çš„æ™¶ç‰‡,ä»è€Œä½¿é“œ(Cu)æ±¡æŸ“å¯¼è‡´çš„æ™¶...</td>\n",
       "      <td>ë³¸ ë°œëª…ì— ì˜í•˜ë©´, êµ¬ë¦¬(Cu) ë°°ì„  ê³µì •ì—ì„œ ë°œìƒí•˜ëŠ” ì˜¤ì—¼ëœ ì›¨ì´í¼ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>æœ¬æ–¹æ¡ˆå…¬å¼€äº†ä½¿ç”¨æ— ç”µæç¯çš„ç…§æ˜ç¯å…·,è¯¥æ— ç”µæç¯é€šè¿‡é«˜é¢‘æ„Ÿåº”çº¿åœˆçš„æ„Ÿåº”ç”µåŠ¨åŠ¿ä½¿ç£·å…‰ä½“å‘å‡ºç”±æ”¾ç”µ...</td>\n",
       "      <td>ë³¸ ê³ ì•ˆì€ ê³ ì£¼íŒŒ ìœ ë„ ì½”ì¼ì˜ ìœ ë„ ê¸°ì „ë ¥ì— ì˜í•˜ì—¬ ë°©ì „ê´€ë‚´ì˜ í”Œë¼ì¦ˆë§ˆ ë°œìƒì— ì˜í•œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>æœ¬å‘æ˜æ¶‰åŠä¸€ç§å•å‘é€šä¿¡è®¾å¤‡,å…¶ä½¿å¾—èƒ½å¤Ÿåœ¨å‘é€ç»ˆç«¯ä¸æ¥æ”¶ç»ˆç«¯ä¹‹é—´è¿›è¡Œå¯é çš„å•å‘é€šä¿¡ã€‚</td>\n",
       "      <td>ë³¸ ë°œëª…ì€ ë‹¨ë°©í–¥ í†µì‹  ì¥ì¹˜ë¡œì„œ, ì†¡ì‹  ë‹¨ë§ê¸°ì™€ ìˆ˜ì‹  ë‹¨ë§ê¸° ì‚¬ì´ì— ì‹ ë¢°ì„± ìˆëŠ” ë‹¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>æœ¬æ–¹æ¡ˆæ¶‰åŠä¸€ç§ç”µç£æ„Ÿåº”åŠ çƒ­è£…ç½®,æ›´å…·ä½“æ¥è¯´æ˜¯æ¶‰åŠäº†è¯†åˆ«ç”¨äºç‚Šå…·çš„å®¹å™¨,å¹¶æ§åˆ¶è¯¥ç”µç£æ„Ÿåº”åŠ çƒ­è£…...</td>\n",
       "      <td>ë³¸ ê³ ì•ˆì€ ì „ì ìœ ë„ê°€ì—´ì¥ì¹˜ë¡œì„œ, ë”ìš± ìƒì„¸í•˜ê²ŒëŠ” ì¡°ë¦¬ê¸°ì— ì‚¬ìš©ë˜ëŠ” ìš©ê¸°ë¥¼ ì‹ë³„í•˜ì—¬...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>æœ¬æ–¹æ¡ˆæ¶‰åŠä½å‹ç»•çº¿ç®¡çš„æ‰‡å½¢éƒ¨åˆ†å’Œæ¨¡åˆ¶å£³ä½“ä¹‹é—´çš„ç»„åˆç»“æ„,æ˜¯ä¸ºäº†åœ¨ä½å‹ç»•çº¿ç®¡çš„æ‰‡å½¢éƒ¨åˆ†å½¢æˆçˆªæ¥...</td>\n",
       "      <td>ë³¸ ê³ ì•ˆì€ ì €ì••ë³´ë¹ˆì˜ íŒŒì´ë¶€ì™€ ëª°ë”©ì¼€ì´ìŠ¤ì˜ ê²°í•©êµ¬ì¡°ì— ê´€í•œ ê²ƒìœ¼ë¡œ, ì €ì••ë³´ë¹ˆì˜ íŒŒì´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>å› æ­¤,ç”±äºæ— éœ€è¯¸å¦‚å•ç‹¬çš„ç„Šæ¥æœºæˆ–å¤¹å…·çš„è®¾å¤‡,ä»…åœ¨ç®€å•åœ°æ’å…¥ç»„è£…å·¥æ—¶çš„æƒ…å†µä¸‹è¿›è¡Œæ—‹é’®çš„å®‰è£…,å› ...</td>\n",
       "      <td>ë”°ë¼ì„œ ë³„ë„ì˜ ìš©ì°©ê¸°ë‚˜ ì§€ê·¸ ë“±ì˜ ì¥ë¹„ì—†ì´ ê°„ë‹¨íˆ ë¼ì›Œì£¼ëŠ” ì¡°ë¦½ê³µìˆ˜ë§Œìœ¼ë¡œ ë…¸ë¸Œì˜ ì„¤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>æ ¹æ®æœ¬å‘æ˜,å…·æœ‰æ— éœ€å†å¤‡ç”¨ç”µæºæ’åº§ä¸­å®‰è£…å¦å¤–çš„å¼€å…³,è€Œæ˜¯åˆ©ç”¨æ— çº¿å¼€å…³æ¥æ§åˆ¶å¤‡ç”¨ç”µæºæ’åº§çš„ä¼˜ç‚¹ã€‚</td>\n",
       "      <td>ë³¸ ë°œëª…ì— ë”°ë¥´ë©´ ëŒ€ê¸°ì „ë ¥ì½˜ì„¼íŠ¸ì— ë³„ë„ë¡œ ìŠ¤ìœ„ì¹˜ë¥¼ ì„¤ì¹˜í•˜ì§€ ì•Šê³ , ë¬´ì„ ìŠ¤ìœ„ì¹˜ë¥¼ ì´ìš©...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>æœ¬å‘æ˜æ˜¯å…³äºåˆ©ç”¨çŸ­ä¿¡ç¡®è®¤ç½‘é¡µé‚®ä»¶çš„æ–¹æ³•åŠç³»ç»Ÿã€‚</td>\n",
       "      <td>ë³¸ ë°œëª…ì€ ë‹¨ë¬¸ë©”ì‹œì§€ë¥¼ ì´ìš©í•œ ì›¹ë©”ì¼ í™•ì¸ ë°©ë²• ë° ì‹œìŠ¤í…œì— ê´€í•œ ê²ƒì´ë‹¤.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                zho_Hans  \\\n",
       "0         æœ¬æ–¹æ¡ˆçš„æ¥è§¦é¢è†¨èƒ€å‹çƒ­ç†”æ–­å™¨æ¶‰åŠç”¨äºåŠ çƒ­è£…ç½®æˆ–åŠ çƒ­éƒ¨çš„æ¥è§¦é¢è†¨èƒ€å¹¶ä¸”æ”¹å–„æ¥è§¦çŠ¶æ€çš„çƒ­ç†”æ–­å™¨ã€‚   \n",
       "1                                   å¯ä»¥æ²¿ç€åˆ‡å‰²çº¿é«˜ç²¾åº¦åœ°åˆ‡å‰²è¦åŠ å·¥çš„ç‰©ä½“ã€‚   \n",
       "2      æ ¹æ®æœ¬å‘æ˜,æœ‰æ•ˆåœ°æ¸…æ´äº†é“œ(Cu)å¸ƒçº¿å·¥è‰ºä¸­äº§ç”Ÿçš„å—æ±¡æŸ“çš„æ™¶ç‰‡,ä»è€Œä½¿é“œ(Cu)æ±¡æŸ“å¯¼è‡´çš„æ™¶...   \n",
       "3      æœ¬æ–¹æ¡ˆå…¬å¼€äº†ä½¿ç”¨æ— ç”µæç¯çš„ç…§æ˜ç¯å…·,è¯¥æ— ç”µæç¯é€šè¿‡é«˜é¢‘æ„Ÿåº”çº¿åœˆçš„æ„Ÿåº”ç”µåŠ¨åŠ¿ä½¿ç£·å…‰ä½“å‘å‡ºç”±æ”¾ç”µ...   \n",
       "4              æœ¬å‘æ˜æ¶‰åŠä¸€ç§å•å‘é€šä¿¡è®¾å¤‡,å…¶ä½¿å¾—èƒ½å¤Ÿåœ¨å‘é€ç»ˆç«¯ä¸æ¥æ”¶ç»ˆç«¯ä¹‹é—´è¿›è¡Œå¯é çš„å•å‘é€šä¿¡ã€‚   \n",
       "...                                                  ...   \n",
       "14995  æœ¬æ–¹æ¡ˆæ¶‰åŠä¸€ç§ç”µç£æ„Ÿåº”åŠ çƒ­è£…ç½®,æ›´å…·ä½“æ¥è¯´æ˜¯æ¶‰åŠäº†è¯†åˆ«ç”¨äºç‚Šå…·çš„å®¹å™¨,å¹¶æ§åˆ¶è¯¥ç”µç£æ„Ÿåº”åŠ çƒ­è£…...   \n",
       "14996  æœ¬æ–¹æ¡ˆæ¶‰åŠä½å‹ç»•çº¿ç®¡çš„æ‰‡å½¢éƒ¨åˆ†å’Œæ¨¡åˆ¶å£³ä½“ä¹‹é—´çš„ç»„åˆç»“æ„,æ˜¯ä¸ºäº†åœ¨ä½å‹ç»•çº¿ç®¡çš„æ‰‡å½¢éƒ¨åˆ†å½¢æˆçˆªæ¥...   \n",
       "14997  å› æ­¤,ç”±äºæ— éœ€è¯¸å¦‚å•ç‹¬çš„ç„Šæ¥æœºæˆ–å¤¹å…·çš„è®¾å¤‡,ä»…åœ¨ç®€å•åœ°æ’å…¥ç»„è£…å·¥æ—¶çš„æƒ…å†µä¸‹è¿›è¡Œæ—‹é’®çš„å®‰è£…,å› ...   \n",
       "14998    æ ¹æ®æœ¬å‘æ˜,å…·æœ‰æ— éœ€å†å¤‡ç”¨ç”µæºæ’åº§ä¸­å®‰è£…å¦å¤–çš„å¼€å…³,è€Œæ˜¯åˆ©ç”¨æ— çº¿å¼€å…³æ¥æ§åˆ¶å¤‡ç”¨ç”µæºæ’åº§çš„ä¼˜ç‚¹ã€‚   \n",
       "14999                            æœ¬å‘æ˜æ˜¯å…³äºåˆ©ç”¨çŸ­ä¿¡ç¡®è®¤ç½‘é¡µé‚®ä»¶çš„æ–¹æ³•åŠç³»ç»Ÿã€‚   \n",
       "\n",
       "                                                kor_Hang  \n",
       "0      ë³¸ ê³ ì•ˆì˜ ì ‘ë©´í™•ì¥ ê°ì˜¨í“¨ì¦ˆëŠ”, ë°œì—´ê¸°êµ¬ë‚˜ ë°œì—´ë¶€ìœ„ì— ëŒ€í•œ ì ‘ì´‰ë©´ì„ í™•ì¥ì‹œí‚´ê³¼ ë™ì‹œ...  \n",
       "1                 ì ˆë‹¨ ì˜ˆì • ë¼ì¸ì— ë”°ë¥¸ ê°€ê³µ ëŒ€ìƒë¬¼ì˜ ê³ ì •ë°€ë„ ì ˆë‹¨ì´ ê°€ëŠ¥í•˜ê²Œ ëœë‹¤.  \n",
       "2      ë³¸ ë°œëª…ì— ì˜í•˜ë©´, êµ¬ë¦¬(Cu) ë°°ì„  ê³µì •ì—ì„œ ë°œìƒí•˜ëŠ” ì˜¤ì—¼ëœ ì›¨ì´í¼ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ...  \n",
       "3      ë³¸ ê³ ì•ˆì€ ê³ ì£¼íŒŒ ìœ ë„ ì½”ì¼ì˜ ìœ ë„ ê¸°ì „ë ¥ì— ì˜í•˜ì—¬ ë°©ì „ê´€ë‚´ì˜ í”Œë¼ì¦ˆë§ˆ ë°œìƒì— ì˜í•œ...  \n",
       "4      ë³¸ ë°œëª…ì€ ë‹¨ë°©í–¥ í†µì‹  ì¥ì¹˜ë¡œì„œ, ì†¡ì‹  ë‹¨ë§ê¸°ì™€ ìˆ˜ì‹  ë‹¨ë§ê¸° ì‚¬ì´ì— ì‹ ë¢°ì„± ìˆëŠ” ë‹¨...  \n",
       "...                                                  ...  \n",
       "14995  ë³¸ ê³ ì•ˆì€ ì „ì ìœ ë„ê°€ì—´ì¥ì¹˜ë¡œì„œ, ë”ìš± ìƒì„¸í•˜ê²ŒëŠ” ì¡°ë¦¬ê¸°ì— ì‚¬ìš©ë˜ëŠ” ìš©ê¸°ë¥¼ ì‹ë³„í•˜ì—¬...  \n",
       "14996  ë³¸ ê³ ì•ˆì€ ì €ì••ë³´ë¹ˆì˜ íŒŒì´ë¶€ì™€ ëª°ë”©ì¼€ì´ìŠ¤ì˜ ê²°í•©êµ¬ì¡°ì— ê´€í•œ ê²ƒìœ¼ë¡œ, ì €ì••ë³´ë¹ˆì˜ íŒŒì´...  \n",
       "14997  ë”°ë¼ì„œ ë³„ë„ì˜ ìš©ì°©ê¸°ë‚˜ ì§€ê·¸ ë“±ì˜ ì¥ë¹„ì—†ì´ ê°„ë‹¨íˆ ë¼ì›Œì£¼ëŠ” ì¡°ë¦½ê³µìˆ˜ë§Œìœ¼ë¡œ ë…¸ë¸Œì˜ ì„¤...  \n",
       "14998  ë³¸ ë°œëª…ì— ë”°ë¥´ë©´ ëŒ€ê¸°ì „ë ¥ì½˜ì„¼íŠ¸ì— ë³„ë„ë¡œ ìŠ¤ìœ„ì¹˜ë¥¼ ì„¤ì¹˜í•˜ì§€ ì•Šê³ , ë¬´ì„ ìŠ¤ìœ„ì¹˜ë¥¼ ì´ìš©...  \n",
       "14999          ë³¸ ë°œëª…ì€ ë‹¨ë¬¸ë©”ì‹œì§€ë¥¼ ì´ìš©í•œ ì›¹ë©”ì¼ í™•ì¸ ë°©ë²• ë° ì‹œìŠ¤í…œì— ê´€í•œ ê²ƒì´ë‹¤.  \n",
       "\n",
       "[15000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2dcf809532ea9",
   "metadata": {},
   "source": [
    "find the max length of the encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f053fd6315b47e9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "language_x = \"zho_Hans\"\n",
    "language_y = \"kor_Hang\"\n",
    "x_train = df_train[language_x].to_list()\n",
    "y_train = df_train[language_y].to_list()\n",
    "x_valid = df_valid[language_x].to_list()\n",
    "y_valid = df_valid[language_y].to_list()\n",
    "\n",
    "# ä»è®­ç»ƒé›†ä¸­æŠ½å‡ºæµ‹è¯•é›†ï¼Œè§„æ¨¡ä¸éªŒè¯é›†ä¸€è‡´\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=len(x_valid), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61fdc162-e4d7-4dd0-b8f2-0f99ae4bb68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜åˆ° CSV æ–‡ä»¶\n",
    "import pandas as pd\n",
    "\n",
    "# åˆ›å»º DataFrame\n",
    "train_df = pd.DataFrame({language_x: x_train, language_y: y_train})\n",
    "valid_df = pd.DataFrame({language_x: x_valid, language_y: y_valid})\n",
    "test_df = pd.DataFrame({language_x: x_test, language_y: y_test})\n",
    "\n",
    "train_df.to_csv('data/train_data.csv', index=False)\n",
    "valid_df.to_csv('data/valid_data.csv', index=False)\n",
    "test_df.to_csv('data/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b0d238363af592",
   "metadata": {},
   "source": [
    "Convert your encodings into torch Datasets object:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "180d0cf0-36a2-4156-8cbd-e712908d0e47",
   "metadata": {},
   "source": [
    "ç¡®å®štokenizerçš„max_lengthï¼š\n",
    "ç†ç”±ï¼š\n",
    "1.è°ƒæ•´ model_max_length å¯ä»¥ç¼©çŸ­è®­ç»ƒæ—¶é—´å’Œå‡å°‘å†…å­˜ä½¿ç”¨ï¼Œå°¤å…¶å½“ä½ çš„æ•°æ®é›†çš„æœ€å¤§é•¿åº¦è¿œå°äºæ¨¡å‹é»˜è®¤çš„æœ€å¤§é•¿åº¦æ—¶ã€‚\n",
    "2.è°ƒæ•´æ˜¯æš‚æ—¶çš„ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­æœ‰æ•ˆï¼Œä½†å¦‚æœä½ æƒ³è¦æ°¸ä¹…æ€§åœ°ä¿å­˜è¿™ä¸ªè®¾å®šï¼Œéœ€è¦åœ¨ä¿å­˜å’ŒåŠ è½½æ¨¡å‹æ—¶ç¡®ä¿é…ç½®æ›´æ–°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f7d25f4-a2eb-4680-9764-2d28670cadca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce2690bb2a8455d91a5b93827a8ebc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% percentile length in the dataset is: 66\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# å‡è®¾ä½ å·²ç»æœ‰æ‰€æœ‰é•¿åº¦çš„åˆ—è¡¨\n",
    "lengths = []\n",
    "\n",
    "texts_all = x_train + y_train + x_valid + y_valid + x_test + y_test\n",
    "for text in tqdm(texts_all):\n",
    "    tokenized_text = tokenizer(text, truncation=False, padding=False)\n",
    "    lengths.append(len(tokenized_text['input_ids']))\n",
    "\n",
    "# ä½¿ç”¨95%åˆ†ä½æ•°æ¥ç¡®å®šmax_length\n",
    "max_length = int(np.percentile(lengths, 95))\n",
    "print(f\"The 95% percentile length in the dataset is: {max_length}\")\n",
    "\n",
    "tokenizer.max_length = max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b3c899-5e5a-432f-8daa-dc4543bf0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing - source:zho_Hans, target:kor_Hang\n"
     ]
    }
   ],
   "source": [
    "# Note: we're now creating separate encodings for the inputs and outputs.\n",
    "# truncation: truncate the sequence to a shorter length, because sometimes a sequence may be too long for a model to handle\n",
    "# padding: Padding is a strategy for ensuring tensors are rectangular by adding a special padding token to shorter sentences.\n",
    "#     True or 'longest': Pad to the longest sequence in the batch (or no padding if only a single sequence if provided).\n",
    "#     'max_length': Pad to a maximum length specified with the argument max_length or to the maximum acceptable input length for the model if that argument is not provided.\n",
    "#     False or 'do_not_pad' (default): No padding (i.e., can output a batch with sequences of different lengths).\n",
    "# return_tensors: If set 'pt', will return tensors instead of list of python integers. Acceptable values are PyTorch torch.Tensor objects.\n",
    "# max_length (int, optional): Controls the maximum length to use by one of the truncation/padding parameters.\n",
    "tokenizer.src_lang = language_x\n",
    "tokenizer.tgt_lang = language_y\n",
    "print(\"tokenizing - source:{}, target:{}\".format(language_x, language_y))\n",
    "train_encodings = tokenizer(x_train, text_target=y_train, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "valid_encodings = tokenizer(x_valid, text_target=y_valid, truncation=True, padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cbba6ff-a7e2-4d0d-bb9f-f92f4dfc797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = {key: val[index] for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e174377-b96b-449d-a5f8-e8dcda289d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranslationDataset(train_encodings)\n",
    "valid_dataset = TranslationDataset(valid_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eace3117637b2e4",
   "metadata": {},
   "source": [
    "Load the pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a645a12389e7bf5f",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9edf04b785e4cb9",
   "metadata": {},
   "source": [
    "Define your training arguments and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d93029063caf5b0c",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model_name = \"zh2ko_based_on_{0}\".format(model_name)\n",
    "\n",
    "new_model_dir = os.path.join(data_disk_dir, new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27077c1f4b1abe29",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, IntervalStrategy\n",
    "\n",
    "# æ¯1/5 Epochå¤„éªŒè¯ã€è®°å½•ã€ä¿å­˜ä¸€æ¬¡\n",
    "log_steps = len(x_train) / 5\n",
    "\n",
    "# fp16ï¼šåŠç²¾åº¦è¿ç®—ï¼Œå¯ç”¨åæé«˜ä¸€å€ä»¥ä¸Šè¿ç®—é€Ÿåº¦ï¼Œä¸å½±å“loss\n",
    "# gradient_accumulation_stepsï¼šstepsè¶Šå¤§ï¼Œé€Ÿåº¦è¶Šå¿«ï¼Œlossè¶Šé«˜\n",
    "# gradient_checkpointingï¼šå¯ç”¨åï¼Œé™ä½30%å·¦å³é€Ÿåº¦ï¼ŒèŠ‚çœæ˜¾å­˜2/3\n",
    "# per_device_train_batch_sizeï¼šsizeè¶Šå¤§ï¼ŒGPUå ç”¨ç‡è¶Šå¤§ï¼Œé€Ÿåº¦è¶Šå¿«ï¼Œlossè¶Šé«˜ï¼Œå‡ ä¹æˆæ­£æ¯”\n",
    "training_args = TrainingArguments(new_model_dir,\n",
    "                                  num_train_epochs=3,\n",
    "                                  per_device_eval_batch_size=1,\n",
    "                                  per_device_train_batch_size=1,\n",
    "                                  gradient_accumulation_steps=1,\n",
    "                                  gradient_checkpointing=False,\n",
    "                                  fp16=True,\n",
    "                                  warmup_ratio=0.1,\n",
    "                                  eval_strategy=IntervalStrategy.STEPS,\n",
    "                                  eval_steps=log_steps,\n",
    "                                  logging_strategy=IntervalStrategy.STEPS,\n",
    "                                  logging_steps=log_steps,\n",
    "                                  save_strategy=IntervalStrategy.STEPS,\n",
    "                                  save_steps=log_steps,\n",
    "                                  save_total_limit=1,\n",
    "                                  load_best_model_at_end=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f16d4747195f6595",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='315000' max='315000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [315000/315000 20:12:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.247400</td>\n",
       "      <td>0.050068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.044697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.041781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.039563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.038448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.037444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147000</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.036694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168000</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.036033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189000</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.035323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.034650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.034662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252000</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.034440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273000</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.034097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294000</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.033849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.033702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 200}\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 200}\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 200}\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 200}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 200}\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=315000, training_loss=0.11845102267795139, metrics={'train_runtime': 72778.1642, 'train_samples_per_second': 4.328, 'train_steps_per_second': 4.328, 'total_flos': 6.8263794966528e+17, 'train_loss': 0.11845102267795139, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,  # the instantiated ğŸ¤— Transformers model to be trained\n",
    "    args=training_args,  # training arguments, defined above\n",
    "    train_dataset=train_dataset,  # training dataset\n",
    "    eval_dataset=valid_dataset,  # valid dataset\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd500d4370c1be89",
   "metadata": {},
   "source": [
    "Save your fine-tuned model and tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4947d832b548d386",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 200}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('autodl-tmp/zh2ko_based_on_nllb-200-distilled-600M/tokenizer_config.json',\n",
       " 'autodl-tmp/zh2ko_based_on_nllb-200-distilled-600M/special_tokens_map.json',\n",
       " 'autodl-tmp/zh2ko_based_on_nllb-200-distilled-600M/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(new_model_dir)\n",
    "tokenizer.save_pretrained(new_model_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aef48330-bc9c-4a4e-9f70-c2fd9b30899d",
   "metadata": {},
   "source": [
    "Predict & Calculate test loss & BLEU score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf8b6eea-ae91-40e1-b8ac-9b49cf1aab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(x_test, text_target=y_test, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "test_dataset = TranslationDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e70226d3-c113-4810-9f43-85331b9e2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ï¼ï¼ï¼çŒœæµ‹Transformerçš„åŸç”ŸTrainerå­˜åœ¨æ˜¾å­˜æ³„éœ²çš„é—®é¢˜ï¼Œæ ¹æ®è®ºå›ä¸Šçš„ç¥è´´ï¼Œåšå‡ºå¦‚ä¸‹ä¿®æ”¹ï¼š\n",
    "# https://discuss.huggingface.co/t/cuda-out-of-memory-when-using-trainer-with-compute-metrics/2941/13\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"\n",
    "    Original Trainer may have a memory leak. \n",
    "    This is a workaround to avoid storing too many tensors that are not needed.\n",
    "    \"\"\"\n",
    "    pred_ids = torch.argmax(logits[0], dim=-1)\n",
    "    return pred_ids, labels\n",
    "\n",
    "\n",
    "# æ·»åŠ  preprocess_logits_for_metrics å‡½æ•°\n",
    "trainer.preprocess_logits_for_metrics = preprocess_logits_for_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45c4b896-1987-4fd4-9fa1-c7e994804182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¿›è¡Œé¢„æµ‹\n",
    "test_results = trainer.predict(test_dataset)\n",
    "\n",
    "# è·å–é¢„æµ‹ç»“æœ\n",
    "predictions = test_results.predictions\n",
    "labels = test_results.label_ids\n",
    "metrics = test_results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "124a2360-69bf-444a-ad49-e72528bfc1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.03576750308275223,\n",
       " 'test_runtime': 655.6582,\n",
       " 'test_samples_per_second': 22.878,\n",
       " 'test_steps_per_second': 22.878}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è¾“å‡ºè¯„ä¼°æŒ‡æ ‡\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cb52f25-cbe6-4565-b0ae-947b06f6a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "references_array, target_texts_array = predictions\n",
    "\n",
    "# å¯¹ä¸¤ä¸ªæ•°ç»„ä¸­çš„æ¯ä¸€ä¸ªç¼–ç è¿›è¡Œè§£ç \n",
    "references = [tokenizer.decode(encoding, skip_special_tokens=True) for encoding in references_array]\n",
    "target_texts = [tokenizer.decode(encoding, skip_special_tokens=True) for encoding in target_texts_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94615516-4ec2-4882-87a7-6173ecbda34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_texts</th>\n",
       "      <th>target_texts</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>æä¾›äº†ä¸€ç§é€šè¿‡è¾“å‡ºåœ¨ç§»åŠ¨é€šä¿¡ç»ˆç«¯ä¸Šæ˜¾ç¤ºçš„é™„åŠ å†…å®¹ä½œä¸ºå¹¿å‘Šæ•°æ®æ¥é™ä½ç»ˆç«¯çš„ä»·æ ¼å¹¶é™ä½é€šä¿¡æˆæœ¬çš„æ–¹æ³•ã€‚</td>\n",
       "      <td>ì´ë™í†µì‹  ë‹¨ë§ê¸°ì—ì„œ í‘œì‹œë˜ëŠ” ë¶€ê°€ ë‚´ìš©ì„ ê´‘ê³  ë°ì´í„°ë¡œ ì¶œë ¥í•˜ë„ë¡ í•˜ì—¬ ë‹¨ë§ê¸°ì˜ ê°€...</td>\n",
       "      <td>ì´ë™í†µì‹  ë‹¨ë§ê¸°ì— í‘œì‹œë˜ëŠ” ë¶€ê°€ ì»¨ ê´‘ê³  ë°ì´í„°ë¡œ ì¶œë ¥í•˜ì—¬ í•¨ ë‹¨ë§ê¸°ì˜ ê°€ê²©ì„ ë‚®ì¶”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>å½“åœ¨ç¬¬ä¹æ­¥ä¸­ç¡®å®šçš„ç¯å¢ƒäº®åº¦è¾ƒäº®æ—¶,å°†ç…§åŸæ ·è¾“å‡ºåœ¨ç¬¬å››,ç¬¬å…­å’Œç¬¬ä¸ƒæ­¥ä¸­ç¡®å®šçš„å£°éŸ³å€¼,å¹¶åœ¨ç¬¬åä¸€...</td>\n",
       "      <td>ìƒê¸° ì œ 9 ë‹¨ê³„ì—ì„œ íŒë³„í•œ ì£¼ë³€ ë°ê¸°ê°€ ë°ì€ ê²½ìš°, ìƒê¸° ì œ 4, 6, 7 ë‹¨ê³„ì—...</td>\n",
       "      <td>ìƒê¸° ì œ9ë‹¨ ê²°ì •ì •ëœ ì£¼ ë°ê¸°ê°€ ë° ê²½ìš°ì—ëŠ”, ìƒê¸° ì œ 4, 6, 7 ë‹¨ê³„ì—ì„œ íŒëœ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>æœ‰æ•ˆåœ°ä½¿ç”¨å¸¦æ‘„åƒå¤´çš„æ‰‹æœºç­‰ä¸­å®‰è£…çš„å‘å…‰äºŒæç®¡(LED)ã€‚</td>\n",
       "      <td>ì¹´ë©”ë¼ ë¶€ì°© íœ´ëŒ€ ì „í™”ê¸° ë“±ì— ì„¤ì¹˜ëœ LEDë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì´ìš©í•œë‹¤.</td>\n",
       "      <td>ì¹´ë©”ë¼ê°€ì°© íœ´ëŒ€í° ì „í™”ê¸° ë“±ì— ì„¤ì¹˜ëœ ë°œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>å…¶æ¶‰åŠåœ¨å°†æ™¶åœ†ä¼ é€è‡³å·¥è‰ºè…”ä½“çš„è¿‡ç¨‹å’Œå¯¹æ™¶åœ†è¿›è¡Œèš€åˆ»å·¥è‰ºçš„è¿‡ç¨‹ä¸­å‡å°‘æ™¶åœ†å·¥è‰ºé¢æ±¡æŸ“çš„åŠå¯¼ä½“è£…ç½®...</td>\n",
       "      <td>ì›¨ì´í¼ë¥¼ ê³µì •ì±”ë²„ë¡œ ì´ì†¡ì‹œí‚¤ëŠ” ê³¼ì •ê³¼ ì›¨ì´í¼ì— ì‹ê° ê³µì •ì„ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ì—ì„œ ì›¨ì´í¼...</td>\n",
       "      <td>ì›¨ì´í¼ë¥¼ ê³µì •ì±”ë²„ë¡œ ì´ì†¡í•˜ëŠ” ê³µì •ê³¼ ì›¨ì´í¼ë¥¼ ëŒ€í•œê°ê³µì •ì„ ì§„í–‰í•˜ëŠ” ê³¼ì •ì—ì„œ ì›¨ì´í¼ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>å…¶æä¾›æœ‰æœºå‘å…‰å™¨ä»¶,è¯¥æœ‰æœºå‘å…‰å™¨ä»¶èƒ½å¤Ÿå°†ä»æœ‰æœºå‘å…‰å•å…ƒå‘å‡ºçš„å…‰èšé›†åˆ°ä¸€ä¸ªåœ°æ–¹ä»¥æé«˜å…‰åˆ©ç”¨æ•ˆç‡...</td>\n",
       "      <td>ìœ ê¸° ë°œê´‘ì…€ì—ì„œ ë°©ì¶œë˜ëŠ” ë¹›ì„ í•œê³³ìœ¼ë¡œ ì§‘ì¤‘ì‹œì¼œ ê´‘ ì´ìš© íš¨ìœ¨ì„ í–¥ìƒì‹œí‚¤ê³ , ì¸ì ‘ ...</td>\n",
       "      <td>ìœ ê¸°ë°œê´‘ë¶€ë¡œë¶€í„° ë°œì¶œëœ ê´‘ í•œ ê³³ìœ¼ë¡œì— ì§‘ì‹œì¼œ ê´‘ ì´ìš© íš¨ìœ¨ì„ ë†’ì‹œí‚¤ê³  ì¸ ì¸ì ‘í•œì†Œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>æ ¹æ®æœ¬å‘æ˜çš„é˜²æ½®é˜²æ¹¿é…ç”µç®±çš„æ„é€ å¦‚ä¸‹ã€‚</td>\n",
       "      <td>ë³¸ ë°œëª…ì— ì˜í•œ ëƒ‰ê° ë°©ìŠµ ë°°ì „í•¨ì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ëœë‹¤.</td>\n",
       "      <td>ë³¸ ë°œëª…ì— ë”°ë¥¸ ë°©ìŠµìˆ˜ìŠµ ë°°ì „í•¨ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ëœë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>æœ¬å‘æ˜ä¸ºäº†å°„é¢‘å¡ä¸å°„é¢‘ç»ˆç«¯æœºé—´çš„ç•…é€šé€šä¿¡,æå‡ºäº†å°„é¢‘ç»ˆç«¯æœºä¸Šé™„åŠ çš„æœºæ¢°è£…ç½®å’Œä¸ºé©±åŠ¨è¯¥è£…ç½®çš„ç”µ...</td>\n",
       "      <td>ë³¸ ë°œëª…ì€ RFì¹´ë“œì™€ RFë‹¨ë§ê¸°ê°„ì˜ ì›í™œí•œ í†µì‹ ì„ ìœ„í•˜ì—¬ RFë‹¨ë§ê¸°ì— ì¶”ê°€ë  ê¸°ê³„ì ...</td>\n",
       "      <td>ë³¸ ë°œëª…ì€ RFì¹´ë“œì™€ RFë‹¨ë§ê¸°ê°„ì˜ ì›í™œí•œ í†µì‹ ì„ ìœ„í•´ RFë‹¨ë§ê¸°ì— ë¶€ë˜ëŠ” ìˆ˜ì¥ ì¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>æœ¬æ–¹æ¡ˆæ¶‰åŠé€šè¿‡å‘é€å’Œæ¥æ”¶éŸ³å“ä¿¡å·æ¥æ§åˆ¶è®¾å¤‡çš„æ— ç”µæºè¿œç¨‹æ§åˆ¶è®¾å¤‡ã€‚</td>\n",
       "      <td>ë³¸ ê³ ì•ˆì€ ìŒí–¥ì‹ í˜¸ì˜ ì†¡ìˆ˜ì‹ ì— ì˜í•´ ê¸°ê¸°ë¥¼ ì œì–´í•˜ëŠ” ë¬´ì „ì› ì›ê²©ì œì–´ì¥ì¹˜ì— ê´€í•œ ê²ƒì´ë‹¤.</td>\n",
       "      <td>ë³¸ ê³ ì•ˆì€ ì˜¤í–¥ì‹ í˜¸ë¥¼ ì†¡ìˆ˜ì‹ ì„ìœ¼ë¡œ ì˜í•´ ê¸°ê¸°ë¥¼ ì œì–´í•˜ëŠ” ë¬´ì „ì› ì›ê²©ì œì–´ì¥ì¹˜ì— ê´€í•œ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>æœ¬å‘æ˜æ¶‰åŠä¸€ç§åœ¨å‘¼å«ä¸­æ”¹å˜ç”¨äºç§»åŠ¨é€šä¿¡ç»ˆç«¯çš„FAä»¥æ ¹æ®å‘¼å«æœŸé—´çš„ç³»ç»Ÿè´Ÿè½½å®æ—¶åœ°æ”¹å˜ç»ˆç«¯çš„FA...</td>\n",
       "      <td>ë³¸ ë°œëª…ì€ í†µí™” ì¤‘ì— ì‹œìŠ¤í…œì˜ ë¡œë“œì— ë”°ë¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹¨ë§ì˜ FAë¥¼ ë³€ê²½í•˜ë„ë¡ í•˜ëŠ”...</td>\n",
       "      <td>ë³¸ ë°œëª…ì€ í†µí™” ì¤‘ ì‹œìŠ¤í…œ ë¶€ë“œì— ë”°ë¼ ë‹¨ìœ¼ë¡œ ë‹¨ë§ì˜ FAë¥¼ ë³€ê²½í•˜ë„ë¡ í†µí™” í†µí™”ì¤‘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>è¿›ä¸€æ­¥åœ°,é“…è“„ç”µæ± æˆ–é”‚ç¦»å­ç”µæ± å…·æœ‰äº§å“çš„æ‰‹åŠ¨é€‰æ‹©å¼€å…³,ä½¿ç”¨æˆ·å¯ä»¥æ ¹æ®éœ€è¦ä»…é€‰æ‹©è¯¥ç”µæ± å¹¶å……ç”µã€‚</td>\n",
       "      <td>ë” ë‚˜ì•„ê°€ì„œ ë‚©ì¶•ì „ì§€ ë˜ëŠ” ë¦¬ ì´ì˜¨ì „ì§€ëŠ” ì œí’ˆì˜ ìˆ˜ë™ì ì¸ ì„ íƒ ìŠ¤ìœ„ì¹˜ë¥¼ ë‘ì–´ ì‚¬ìš©ì...</td>\n",
       "      <td>ë‚˜ì•„ê°€ ë‚˜ì•„ê°€,,ì¶•ì „ì§€ë‚˜ ë¦¬ì´ì˜¨ì „ì§€ëŠ” ì œí’ˆì˜ ìˆ˜ë™ì„  ì„ íƒìŠ¤ì¹˜ë¥¼ êµ¬ì–´ ì‚¬ìš©ìê°€ë¡œ í•˜ì—¬...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            source_texts  \\\n",
       "0      æä¾›äº†ä¸€ç§é€šè¿‡è¾“å‡ºåœ¨ç§»åŠ¨é€šä¿¡ç»ˆç«¯ä¸Šæ˜¾ç¤ºçš„é™„åŠ å†…å®¹ä½œä¸ºå¹¿å‘Šæ•°æ®æ¥é™ä½ç»ˆç«¯çš„ä»·æ ¼å¹¶é™ä½é€šä¿¡æˆæœ¬çš„æ–¹æ³•ã€‚   \n",
       "1      å½“åœ¨ç¬¬ä¹æ­¥ä¸­ç¡®å®šçš„ç¯å¢ƒäº®åº¦è¾ƒäº®æ—¶,å°†ç…§åŸæ ·è¾“å‡ºåœ¨ç¬¬å››,ç¬¬å…­å’Œç¬¬ä¸ƒæ­¥ä¸­ç¡®å®šçš„å£°éŸ³å€¼,å¹¶åœ¨ç¬¬åä¸€...   \n",
       "2                           æœ‰æ•ˆåœ°ä½¿ç”¨å¸¦æ‘„åƒå¤´çš„æ‰‹æœºç­‰ä¸­å®‰è£…çš„å‘å…‰äºŒæç®¡(LED)ã€‚   \n",
       "3      å…¶æ¶‰åŠåœ¨å°†æ™¶åœ†ä¼ é€è‡³å·¥è‰ºè…”ä½“çš„è¿‡ç¨‹å’Œå¯¹æ™¶åœ†è¿›è¡Œèš€åˆ»å·¥è‰ºçš„è¿‡ç¨‹ä¸­å‡å°‘æ™¶åœ†å·¥è‰ºé¢æ±¡æŸ“çš„åŠå¯¼ä½“è£…ç½®...   \n",
       "4      å…¶æä¾›æœ‰æœºå‘å…‰å™¨ä»¶,è¯¥æœ‰æœºå‘å…‰å™¨ä»¶èƒ½å¤Ÿå°†ä»æœ‰æœºå‘å…‰å•å…ƒå‘å‡ºçš„å…‰èšé›†åˆ°ä¸€ä¸ªåœ°æ–¹ä»¥æé«˜å…‰åˆ©ç”¨æ•ˆç‡...   \n",
       "...                                                  ...   \n",
       "14995                                æ ¹æ®æœ¬å‘æ˜çš„é˜²æ½®é˜²æ¹¿é…ç”µç®±çš„æ„é€ å¦‚ä¸‹ã€‚   \n",
       "14996  æœ¬å‘æ˜ä¸ºäº†å°„é¢‘å¡ä¸å°„é¢‘ç»ˆç«¯æœºé—´çš„ç•…é€šé€šä¿¡,æå‡ºäº†å°„é¢‘ç»ˆç«¯æœºä¸Šé™„åŠ çš„æœºæ¢°è£…ç½®å’Œä¸ºé©±åŠ¨è¯¥è£…ç½®çš„ç”µ...   \n",
       "14997                   æœ¬æ–¹æ¡ˆæ¶‰åŠé€šè¿‡å‘é€å’Œæ¥æ”¶éŸ³å“ä¿¡å·æ¥æ§åˆ¶è®¾å¤‡çš„æ— ç”µæºè¿œç¨‹æ§åˆ¶è®¾å¤‡ã€‚   \n",
       "14998  æœ¬å‘æ˜æ¶‰åŠä¸€ç§åœ¨å‘¼å«ä¸­æ”¹å˜ç”¨äºç§»åŠ¨é€šä¿¡ç»ˆç«¯çš„FAä»¥æ ¹æ®å‘¼å«æœŸé—´çš„ç³»ç»Ÿè´Ÿè½½å®æ—¶åœ°æ”¹å˜ç»ˆç«¯çš„FA...   \n",
       "14999     è¿›ä¸€æ­¥åœ°,é“…è“„ç”µæ± æˆ–é”‚ç¦»å­ç”µæ± å…·æœ‰äº§å“çš„æ‰‹åŠ¨é€‰æ‹©å¼€å…³,ä½¿ç”¨æˆ·å¯ä»¥æ ¹æ®éœ€è¦ä»…é€‰æ‹©è¯¥ç”µæ± å¹¶å……ç”µã€‚   \n",
       "\n",
       "                                            target_texts  \\\n",
       "0      ì´ë™í†µì‹  ë‹¨ë§ê¸°ì—ì„œ í‘œì‹œë˜ëŠ” ë¶€ê°€ ë‚´ìš©ì„ ê´‘ê³  ë°ì´í„°ë¡œ ì¶œë ¥í•˜ë„ë¡ í•˜ì—¬ ë‹¨ë§ê¸°ì˜ ê°€...   \n",
       "1      ìƒê¸° ì œ 9 ë‹¨ê³„ì—ì„œ íŒë³„í•œ ì£¼ë³€ ë°ê¸°ê°€ ë°ì€ ê²½ìš°, ìƒê¸° ì œ 4, 6, 7 ë‹¨ê³„ì—...   \n",
       "2                  ì¹´ë©”ë¼ ë¶€ì°© íœ´ëŒ€ ì „í™”ê¸° ë“±ì— ì„¤ì¹˜ëœ LEDë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì´ìš©í•œë‹¤.   \n",
       "3      ì›¨ì´í¼ë¥¼ ê³µì •ì±”ë²„ë¡œ ì´ì†¡ì‹œí‚¤ëŠ” ê³¼ì •ê³¼ ì›¨ì´í¼ì— ì‹ê° ê³µì •ì„ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ì—ì„œ ì›¨ì´í¼...   \n",
       "4      ìœ ê¸° ë°œê´‘ì…€ì—ì„œ ë°©ì¶œë˜ëŠ” ë¹›ì„ í•œê³³ìœ¼ë¡œ ì§‘ì¤‘ì‹œì¼œ ê´‘ ì´ìš© íš¨ìœ¨ì„ í–¥ìƒì‹œí‚¤ê³ , ì¸ì ‘ ...   \n",
       "...                                                  ...   \n",
       "14995                   ë³¸ ë°œëª…ì— ì˜í•œ ëƒ‰ê° ë°©ìŠµ ë°°ì „í•¨ì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ëœë‹¤.   \n",
       "14996  ë³¸ ë°œëª…ì€ RFì¹´ë“œì™€ RFë‹¨ë§ê¸°ê°„ì˜ ì›í™œí•œ í†µì‹ ì„ ìœ„í•˜ì—¬ RFë‹¨ë§ê¸°ì— ì¶”ê°€ë  ê¸°ê³„ì ...   \n",
       "14997   ë³¸ ê³ ì•ˆì€ ìŒí–¥ì‹ í˜¸ì˜ ì†¡ìˆ˜ì‹ ì— ì˜í•´ ê¸°ê¸°ë¥¼ ì œì–´í•˜ëŠ” ë¬´ì „ì› ì›ê²©ì œì–´ì¥ì¹˜ì— ê´€í•œ ê²ƒì´ë‹¤.   \n",
       "14998  ë³¸ ë°œëª…ì€ í†µí™” ì¤‘ì— ì‹œìŠ¤í…œì˜ ë¡œë“œì— ë”°ë¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹¨ë§ì˜ FAë¥¼ ë³€ê²½í•˜ë„ë¡ í•˜ëŠ”...   \n",
       "14999  ë” ë‚˜ì•„ê°€ì„œ ë‚©ì¶•ì „ì§€ ë˜ëŠ” ë¦¬ ì´ì˜¨ì „ì§€ëŠ” ì œí’ˆì˜ ìˆ˜ë™ì ì¸ ì„ íƒ ìŠ¤ìœ„ì¹˜ë¥¼ ë‘ì–´ ì‚¬ìš©ì...   \n",
       "\n",
       "                                              references  \n",
       "0      ì´ë™í†µì‹  ë‹¨ë§ê¸°ì— í‘œì‹œë˜ëŠ” ë¶€ê°€ ì»¨ ê´‘ê³  ë°ì´í„°ë¡œ ì¶œë ¥í•˜ì—¬ í•¨ ë‹¨ë§ê¸°ì˜ ê°€ê²©ì„ ë‚®ì¶”...  \n",
       "1      ìƒê¸° ì œ9ë‹¨ ê²°ì •ì •ëœ ì£¼ ë°ê¸°ê°€ ë° ê²½ìš°ì—ëŠ”, ìƒê¸° ì œ 4, 6, 7 ë‹¨ê³„ì—ì„œ íŒëœ...  \n",
       "2                    ì¹´ë©”ë¼ê°€ì°© íœ´ëŒ€í° ì „í™”ê¸° ë“±ì— ì„¤ì¹˜ëœ ë°œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.  \n",
       "3      ì›¨ì´í¼ë¥¼ ê³µì •ì±”ë²„ë¡œ ì´ì†¡í•˜ëŠ” ê³µì •ê³¼ ì›¨ì´í¼ë¥¼ ëŒ€í•œê°ê³µì •ì„ ì§„í–‰í•˜ëŠ” ê³¼ì •ì—ì„œ ì›¨ì´í¼ ...  \n",
       "4      ìœ ê¸°ë°œê´‘ë¶€ë¡œë¶€í„° ë°œì¶œëœ ê´‘ í•œ ê³³ìœ¼ë¡œì— ì§‘ì‹œì¼œ ê´‘ ì´ìš© íš¨ìœ¨ì„ ë†’ì‹œí‚¤ê³  ì¸ ì¸ì ‘í•œì†Œ...  \n",
       "...                                                  ...  \n",
       "14995                     ë³¸ ë°œëª…ì— ë”°ë¥¸ ë°©ìŠµìˆ˜ìŠµ ë°°ì „í•¨ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ëœë‹¤.  \n",
       "14996  ë³¸ ë°œëª…ì€ RFì¹´ë“œì™€ RFë‹¨ë§ê¸°ê°„ì˜ ì›í™œí•œ í†µì‹ ì„ ìœ„í•´ RFë‹¨ë§ê¸°ì— ë¶€ë˜ëŠ” ìˆ˜ì¥ ì¥...  \n",
       "14997  ë³¸ ê³ ì•ˆì€ ì˜¤í–¥ì‹ í˜¸ë¥¼ ì†¡ìˆ˜ì‹ ì„ìœ¼ë¡œ ì˜í•´ ê¸°ê¸°ë¥¼ ì œì–´í•˜ëŠ” ë¬´ì „ì› ì›ê²©ì œì–´ì¥ì¹˜ì— ê´€í•œ ...  \n",
       "14998  ë³¸ ë°œëª…ì€ í†µí™” ì¤‘ ì‹œìŠ¤í…œ ë¶€ë“œì— ë”°ë¼ ë‹¨ìœ¼ë¡œ ë‹¨ë§ì˜ FAë¥¼ ë³€ê²½í•˜ë„ë¡ í†µí™” í†µí™”ì¤‘...  \n",
       "14999  ë‚˜ì•„ê°€ ë‚˜ì•„ê°€,,ì¶•ì „ì§€ë‚˜ ë¦¬ì´ì˜¨ì „ì§€ëŠ” ì œí’ˆì˜ ìˆ˜ë™ì„  ì„ íƒìŠ¤ì¹˜ë¥¼ êµ¬ì–´ ì‚¬ìš©ìê°€ë¡œ í•˜ì—¬...  \n",
       "\n",
       "[15000 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_texts = x_test\n",
    "\n",
    "df_result = pd.DataFrame({\n",
    "    \"source_texts\": source_texts,\n",
    "    \"target_texts\": target_texts,\n",
    "    \"references\": references,\n",
    "})\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b370b262-c807-45a8-b4fd-6bfe82ea6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"results_of_{0}\".format(new_model_name)\n",
    "df_result.to_excel(\"{0}.xlsx\".format(file_name), index=False)\n",
    "df_result.to_csv(\"{0}.csv\".format(file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64a9293a-7096-4dd3-9f12-26277facdf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7068739162535101"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# corpus_bleu çš„ç»“æœæ›´ç¨³å¥ï¼Œå› ä¸ºå®ƒæ˜¯åŸºäºæ•´ä¸ªè¯­æ–™åº“çš„å¹³å‡åˆ†æ•°è®¡ç®—çš„ï¼Œè€Œ sentence_bleu ä»…åŸºäºå•ä¸ªå¥å­ã€‚\n",
    "# æ³¨ï¼šnltk3.8.1å’Œpython 3.12æœ‰ç‚¹é—®é¢˜ï¼Œè¦ä¹ˆé™ä½pythonç‰ˆæœ¬ï¼Œè¦ä¹ˆæŒ‰ç…§ä»¥ä¸‹é“¾æ¥çš„æŒ‡å¯¼å»ä¿®æ”¹bleu_score.pyæ–‡ä»¶\n",
    "# https://github.com/nltk/nltk/pull/3207\n",
    "# https://github.com/nltk/nltk/blob/develop/nltk/translate/bleu_score.py\n",
    "score = corpus_bleu([[reference] for reference in references], target_texts)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

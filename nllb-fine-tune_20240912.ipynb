{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6cb62a25-f9dc-4ab0-ad41-925ad49d350d",
   "metadata": {},
   "source": [
    "Environment Setup:"
   ]
  },
  {
   "cell_type": "code",
   "id": "b217e314-3a45-4abb-bbf4-fd1b3901bc2b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#å®‰è£…transformersåº“\n",
    "!pip install transformers accelerate scikit-learn numpy pandas openpyxl nltk"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T05:36:46.079290Z",
     "start_time": "2024-09-13T05:36:44.192593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ],
   "id": "d398cd96eebb1fc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "faa2d71c2c68a230",
   "metadata": {},
   "source": [
    "Load the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3e591ab0d8c7532",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "import os\n",
    "\n",
    "data_disk_dir = \"autodl-tmp\"  # æ•°æ®ç›˜dirï¼ˆäº‘GPUå¹³å°ï¼‰\n",
    "model_name = \"nllb-200-distilled-600M\"\n",
    "model_dir = os.path.join(data_disk_dir, model_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "772dbf8a-eb10-4a50-9b1e-683a973649da",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, tgt_lang=None)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c0064f69-3dcc-4b70-9945-a6d8e4ecd1c6",
   "metadata": {},
   "source": [
    "Prepare your training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "id": "104c0cf739ab273c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "data_dir = \"data/027.í•œêµ­ì–´-ì¤‘êµ­ì–´_ë²ˆì—­_ë§ë­‰ì¹˜_1/01.ë°ì´í„°\"\n",
    "csv_train = os.path.join(data_dir, \"1.Training/ì›ì²œë°ì´í„°/ko2zh_patent_1_training.csv\")\n",
    "csv_valid = os.path.join(data_dir, \"2.Validation/ì›ì²œë°ì´í„°/ko2zh_patent_2_validation.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7a503105-8bce-44cc-a840-fbd3ebf8924e",
   "metadata": {},
   "source": [
    "rename_dict = {\"ì¤‘êµ­ì–´\": \"zho_Hans\", \"í•œêµ­ì–´\": \"kor_Hang\"}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e9d46a4e-c959-4431-a1bc-e407723078c3",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load Training Data\n",
    "df_train = pd.read_csv(csv_train)[rename_dict.keys()]\n",
    "df_train.rename(columns=rename_dict, inplace=True)  # rename the columns\n",
    "\n",
    "#load Validation Data\n",
    "df_valid = pd.read_csv(csv_valid)[rename_dict.keys()]\n",
    "df_valid.rename(columns=rename_dict, inplace=True)  # rename the columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22c9918d-2b9d-44d5-b8b6-33258bc8656f",
   "metadata": {},
   "source": [
    "df_train"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "879de305-49f1-46c3-9046-b9406323b8ee",
   "metadata": {},
   "source": [
    "df_valid"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bce2dcf809532ea9",
   "metadata": {},
   "source": [
    "find the max length of the encodings"
   ]
  },
  {
   "cell_type": "code",
   "id": "2f053fd6315b47e9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "language_x = \"zho_Hans\"\n",
    "language_y = \"kor_Hang\"\n",
    "x_train = df_train[language_x].to_list()\n",
    "y_train = df_train[language_y].to_list()\n",
    "x_valid = df_valid[language_x].to_list()\n",
    "y_valid = df_valid[language_y].to_list()\n",
    "\n",
    "# ä»è®­ç»ƒé›†ä¸­æŠ½å‡ºæµ‹è¯•é›†ï¼Œè§„æ¨¡ä¸éªŒè¯é›†ä¸€è‡´\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=len(x_valid), random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61fdc162-e4d7-4dd0-b8f2-0f99ae4bb68d",
   "metadata": {},
   "source": [
    "# ä¿å­˜åˆ° CSV æ–‡ä»¶\n",
    "import pandas as pd\n",
    "\n",
    "# åˆ›å»º DataFrame\n",
    "train_df = pd.DataFrame({language_x: x_train, language_y: y_train})\n",
    "valid_df = pd.DataFrame({language_x: x_valid, language_y: y_valid})\n",
    "test_df = pd.DataFrame({language_x: x_test, language_y: y_test})\n",
    "\n",
    "train_df.to_csv('data/train_data.csv', index=False)\n",
    "valid_df.to_csv('data/valid_data.csv', index=False)\n",
    "test_df.to_csv('data/test_data.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "60b0d238363af592",
   "metadata": {},
   "source": [
    "Convert your encodings into torch Datasets object:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "180d0cf0-36a2-4156-8cbd-e712908d0e47",
   "metadata": {},
   "source": [
    "ç¡®å®štokenizerçš„max_lengthï¼š\n",
    "ç†ç”±ï¼š\n",
    "1.è°ƒæ•´ model_max_length å¯ä»¥ç¼©çŸ­è®­ç»ƒæ—¶é—´å’Œå‡å°‘å†…å­˜ä½¿ç”¨ï¼Œå°¤å…¶å½“ä½ çš„æ•°æ®é›†çš„æœ€å¤§é•¿åº¦è¿œå°äºæ¨¡å‹é»˜è®¤çš„æœ€å¤§é•¿åº¦æ—¶ã€‚\n",
    "2.è°ƒæ•´æ˜¯æš‚æ—¶çš„ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­æœ‰æ•ˆï¼Œä½†å¦‚æœä½ æƒ³è¦æ°¸ä¹…æ€§åœ°ä¿å­˜è¿™ä¸ªè®¾å®šï¼Œéœ€è¦åœ¨ä¿å­˜å’ŒåŠ è½½æ¨¡å‹æ—¶ç¡®ä¿é…ç½®æ›´æ–°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f7d25f4-a2eb-4680-9764-2d28670cadca",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# å‡è®¾ä½ å·²ç»æœ‰æ‰€æœ‰é•¿åº¦çš„åˆ—è¡¨\n",
    "lengths = []\n",
    "\n",
    "texts_all = x_train + y_train + x_valid + y_valid + x_test + y_test\n",
    "for text in tqdm(texts_all):\n",
    "    tokenized_text = tokenizer(text, truncation=False, padding=False)\n",
    "    lengths.append(len(tokenized_text['input_ids']))\n",
    "\n",
    "# ä½¿ç”¨95%åˆ†ä½æ•°æ¥ç¡®å®šmax_length\n",
    "max_length = int(np.percentile(lengths, 95))\n",
    "print(f\"The 95% percentile length in the dataset is: {max_length}\")\n",
    "\n",
    "tokenizer.max_length = max_length"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2b3c899-5e5a-432f-8daa-dc4543bf0427",
   "metadata": {},
   "source": [
    "# Note: we're now creating separate encodings for the inputs and outputs.\n",
    "# truncation: truncate the sequence to a shorter length, because sometimes a sequence may be too long for a model to handle\n",
    "# padding: Padding is a strategy for ensuring tensors are rectangular by adding a special padding token to shorter sentences.\n",
    "#     True or 'longest': Pad to the longest sequence in the batch (or no padding if only a single sequence if provided).\n",
    "#     'max_length': Pad to a maximum length specified with the argument max_length or to the maximum acceptable input length for the model if that argument is not provided.\n",
    "#     False or 'do_not_pad' (default): No padding (i.e., can output a batch with sequences of different lengths).\n",
    "# return_tensors: If set 'pt', will return tensors instead of list of python integers. Acceptable values are PyTorch torch.Tensor objects.\n",
    "# max_length (int, optional): Controls the maximum length to use by one of the truncation/padding parameters.\n",
    "tokenizer.src_lang = language_x\n",
    "tokenizer.tgt_lang = language_y\n",
    "print(\"tokenizing - source:{}, target:{}\".format(language_x, language_y))\n",
    "print(\"train encodings...\")\n",
    "train_encodings = tokenizer(x_train, text_target=y_train, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "print(\"valid encodings...\")\n",
    "valid_encodings = tokenizer(x_valid, text_target=y_valid, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "print(\"test encodings...\")\n",
    "test_encodings = tokenizer(x_test, text_target=y_test, truncation=True, padding=\"max_length\", return_tensors=\"pt\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9cbba6ff-a7e2-4d0d-bb9f-f92f4dfc797e",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = {key: val[index] for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e174377-b96b-449d-a5f8-e8dcda289d59",
   "metadata": {},
   "source": [
    "train_dataset = TranslationDataset(train_encodings)\n",
    "valid_dataset = TranslationDataset(valid_encodings)\n",
    "test_dataset = TranslationDataset(test_encodings)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2eace3117637b2e4",
   "metadata": {},
   "source": [
    "Load the pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "id": "a645a12389e7bf5f",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir, device_map=\"auto\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b9edf04b785e4cb9",
   "metadata": {},
   "source": [
    "Define your training arguments and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "id": "d93029063caf5b0c",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "new_model_name = \"zh2ko_based_on_{0}\".format(model_name)\n",
    "\n",
    "new_model_dir = os.path.join(data_disk_dir, new_model_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "27077c1f4b1abe29",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "from transformers import Trainer, TrainingArguments, IntervalStrategy\n",
    "\n",
    "# æ¯1/5 Epochå¤„éªŒè¯ã€è®°å½•ã€ä¿å­˜ä¸€æ¬¡\n",
    "log_steps = len(x_train) / 5\n",
    "\n",
    "# fp16ï¼šåŠç²¾åº¦è¿ç®—ï¼Œå¯ç”¨åæé«˜ä¸€å€ä»¥ä¸Šè¿ç®—é€Ÿåº¦ï¼Œä¸å½±å“loss\n",
    "# gradient_accumulation_stepsï¼šstepsè¶Šå¤§ï¼Œé€Ÿåº¦è¶Šå¿«ï¼Œlossè¶Šé«˜\n",
    "# gradient_checkpointingï¼šå¯ç”¨åï¼Œé™ä½30%å·¦å³é€Ÿåº¦ï¼ŒèŠ‚çœæ˜¾å­˜2/3\n",
    "# per_device_train_batch_sizeï¼šsizeè¶Šå¤§ï¼ŒGPUå ç”¨ç‡è¶Šå¤§ï¼Œé€Ÿåº¦è¶Šå¿«ï¼Œlossè¶Šé«˜ï¼Œå‡ ä¹æˆæ­£æ¯”\n",
    "training_args = TrainingArguments(new_model_dir,\n",
    "                                  num_train_epochs=10,\n",
    "                                  per_device_eval_batch_size=1,\n",
    "                                  per_device_train_batch_size=1,\n",
    "                                  gradient_accumulation_steps=1,\n",
    "                                  gradient_checkpointing=False,\n",
    "                                  fp16=True,\n",
    "                                  warmup_ratio=0.1,\n",
    "                                  eval_strategy=IntervalStrategy.STEPS,\n",
    "                                  eval_steps=log_steps,\n",
    "                                  logging_strategy=IntervalStrategy.STEPS,\n",
    "                                  logging_steps=log_steps,\n",
    "                                  save_strategy=IntervalStrategy.STEPS,\n",
    "                                  save_steps=log_steps,\n",
    "                                  save_total_limit=1,\n",
    "                                  load_best_model_at_end=True\n",
    "                                  )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f16d4747195f6595",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "\n",
    "# ï¼ï¼ï¼çŒœæµ‹Transformerçš„åŸç”ŸTrainerå­˜åœ¨æ˜¾å­˜æ³„éœ²çš„é—®é¢˜ï¼Œæ ¹æ®è®ºå›ä¸Šçš„ç¥è´´ï¼Œåšå‡ºå¦‚ä¸‹ä¿®æ”¹ï¼š\n",
    "# https://discuss.huggingface.co/t/cuda-out-of-memory-when-using-trainer-with-compute-metrics/2941/13\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"\n",
    "    Original Trainer may have a memory leak. \n",
    "    This is a workaround to avoid storing too many tensors that are not needed.\n",
    "    \"\"\"\n",
    "    pred_ids = torch.argmax(logits[0], dim=-1)\n",
    "    return pred_ids, labels\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,  # the instantiated ğŸ¤— Transformers model to be trained\n",
    "    args=training_args,  # training arguments, defined above\n",
    "    train_dataset=train_dataset,  # training dataset\n",
    "    eval_dataset=valid_dataset,  # valid dataset\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "abcecbf0-e9de-428c-a366-4b1cf61453be",
   "metadata": {},
   "source": [
    "Test the base model before fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c799af7-5d54-458c-b4af-6866456347ab",
   "metadata": {},
   "source": [
    "# åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¿›è¡Œé¢„æµ‹\n",
    "test_results = trainer.predict(test_dataset)\n",
    "\n",
    "# è·å–é¢„æµ‹ç»“æœ\n",
    "predictions = test_results.predictions\n",
    "labels = test_results.label_ids\n",
    "metrics = test_results.metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da5df31d-fbbd-43d6-a28c-254b30fee8d6",
   "metadata": {},
   "source": [
    "# è¾“å‡ºè¯„ä¼°æŒ‡æ ‡\n",
    "metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d9a315c-4e2c-4496-9e65-0c3b60cb2d94",
   "metadata": {},
   "source": [
    "# è§£ç \n",
    "target_texts_array, references_array = predictions\n",
    "target_texts = [tokenizer.decode(encoding, skip_special_tokens=True) for encoding in target_texts_array]\n",
    "references = [tokenizer.decode(encoding, skip_special_tokens=True) for encoding in references_array]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0a1f77e9-9268-421c-b894-7b0a639d1827",
   "metadata": {},
   "source": [
    "source_texts = x_test\n",
    "\n",
    "df_result = pd.DataFrame({\n",
    "    \"source_texts\": source_texts,\n",
    "    \"target_texts\": target_texts,\n",
    "    \"references\": references,\n",
    "})\n",
    "df_result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "033b954f-60c3-4dcc-a937-a1b74ed61d16",
   "metadata": {},
   "source": [
    "file_name = \"results_of_{0}\".format(model_name)\n",
    "df_result.to_excel(\"{0}.xlsx\".format(file_name), index=False)\n",
    "df_result.to_csv(\"{0}.csv\".format(file_name), index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13b3d7de-b885-4bf1-8aa4-64a95fd506a2",
   "metadata": {},
   "source": [
    "from konlpy.tag import Okt\n",
    "# from konlpy.tag import Mecab # Warning:KoNLPyâ€™s Mecab() class is not supported on Windows machines.\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# corpus_bleu çš„ç»“æœæ›´ç¨³å¥ï¼Œå› ä¸ºå®ƒæ˜¯åŸºäºæ•´ä¸ªè¯­æ–™åº“çš„å¹³å‡åˆ†æ•°è®¡ç®—çš„ï¼Œè€Œ sentence_bleu ä»…åŸºäºå•ä¸ªå¥å­ã€‚\n",
    "# æ³¨ï¼šnltk3.8.1å’Œpython 3.12æœ‰ç‚¹é—®é¢˜ï¼Œè¦ä¹ˆé™ä½pythonç‰ˆæœ¬ï¼Œè¦ä¹ˆæŒ‰ç…§ä»¥ä¸‹é“¾æ¥çš„æŒ‡å¯¼å»ä¿®æ”¹bleu_score.pyæ–‡ä»¶\n",
    "# https://github.com/nltk/nltk/pull/3207\n",
    "# https://github.com/nltk/nltk/blob/develop/nltk/translate/bleu_score.py\n",
    "references_okt = [[Okt().morphs(reference)] for reference in references]\n",
    "target_texts_okt = [Okt().morphs(target_text) for target_text in target_texts]\n",
    "score = corpus_bleu(references_okt, target_texts_okt)\n",
    "score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "7d2d0e37-779b-4f6b-afc9-befcc62bb2dd",
   "metadata": {},
   "source": [
    "Start fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "id": "0b838ba6-546e-416a-969a-8b558358c71d",
   "metadata": {},
   "source": [
    "# trainer.train(resume_from_checkpoint=True)\n",
    "# trainer.train(resume_from_checkpoint=\"autodl-tmp/zh2ko_based_on_nllb-200-distilled-600M/checkpoint-315000\")\n",
    "trainer.train(resume_from_checkpoint=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bd500d4370c1be89",
   "metadata": {},
   "source": [
    "Save your fine-tuned model and tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "id": "4947d832b548d386",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "trainer.save_model(new_model_dir)\n",
    "tokenizer.save_pretrained(new_model_dir)\n",
    "trainer.save_state()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "aef48330-bc9c-4a4e-9f70-c2fd9b30899d",
   "metadata": {},
   "source": [
    "Predict & Calculate test loss & BLEU score:"
   ]
  },
  {
   "cell_type": "code",
   "id": "45c4b896-1987-4fd4-9fa1-c7e994804182",
   "metadata": {},
   "source": [
    "# åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¿›è¡Œé¢„æµ‹\n",
    "test_results = trainer.predict(test_dataset)\n",
    "\n",
    "# è·å–é¢„æµ‹ç»“æœ\n",
    "predictions = test_results.predictions\n",
    "labels = test_results.label_ids\n",
    "metrics = test_results.metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "124a2360-69bf-444a-ad49-e72528bfc1df",
   "metadata": {},
   "source": [
    "# è¾“å‡ºè¯„ä¼°æŒ‡æ ‡\n",
    "metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7cb52f25-cbe6-4565-b0ae-947b06f6a15f",
   "metadata": {},
   "source": [
    "target_texts_array, references_array = predictions\n",
    "\n",
    "# å¯¹ä¸¤ä¸ªæ•°ç»„ä¸­çš„æ¯ä¸€ä¸ªç¼–ç è¿›è¡Œè§£ç \n",
    "target_texts = [tokenizer.decode(encoding, skip_special_tokens=True) for encoding in target_texts_array]\n",
    "references = [tokenizer.decode(encoding, skip_special_tokens=True) for encoding in references_array]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94615516-4ec2-4882-87a7-6173ecbda34c",
   "metadata": {},
   "source": [
    "source_texts = x_test\n",
    "\n",
    "df_result = pd.DataFrame({\n",
    "    \"source_texts\": source_texts,\n",
    "    \"target_texts\": target_texts,\n",
    "    \"references\": references,\n",
    "})\n",
    "df_result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b370b262-c807-45a8-b4fd-6bfe82ea6d0a",
   "metadata": {},
   "source": [
    "file_name = \"results_of_{0}\".format(new_model_name)\n",
    "df_result.to_excel(\"{0}.xlsx\".format(file_name), index=False)\n",
    "df_result.to_csv(\"{0}.csv\".format(file_name), index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64a9293a-7096-4dd3-9f12-26277facdf8b",
   "metadata": {},
   "source": [
    "from konlpy.tag import Okt\n",
    "# from konlpy.tag import Mecab # Warning:KoNLPyâ€™s Mecab() class is not supported on Windows machines.\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# corpus_bleu çš„ç»“æœæ›´ç¨³å¥ï¼Œå› ä¸ºå®ƒæ˜¯åŸºäºæ•´ä¸ªè¯­æ–™åº“çš„å¹³å‡åˆ†æ•°è®¡ç®—çš„ï¼Œè€Œ sentence_bleu ä»…åŸºäºå•ä¸ªå¥å­ã€‚\n",
    "# æ³¨ï¼šnltk3.8.1å’Œpython 3.12æœ‰ç‚¹é—®é¢˜ï¼Œè¦ä¹ˆé™ä½pythonç‰ˆæœ¬ï¼Œè¦ä¹ˆæŒ‰ç…§ä»¥ä¸‹é“¾æ¥çš„æŒ‡å¯¼å»ä¿®æ”¹bleu_score.pyæ–‡ä»¶\n",
    "# https://github.com/nltk/nltk/pull/3207\n",
    "# https://github.com/nltk/nltk/blob/develop/nltk/translate/bleu_score.py\n",
    "references_okt = [[Okt().morphs(reference)] for reference in references]\n",
    "target_texts_okt = [Okt().morphs(target_text) for target_text in target_texts]\n",
    "score = corpus_bleu(references_okt, target_texts_okt)\n",
    "score"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
